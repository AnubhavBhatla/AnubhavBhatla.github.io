---
---

@inproceedings{maya,
author = {Bhatla, Anubhav and Navneet and Panda, Biswabandan},
title = {The Maya Cache: A Storage-efficient and Secure Fully-associative Last-level Cache},
year = {2024},
pdf = {MAYA.pdf},
html = {https://ieeexplore.ieee.org/abstract/document/10609602},
preview = {isca.jpg},
booktitle = {International Symposium on Computer Architecture},
publisher = {International Symposium on Computer Architecture},
location = {Buenos Aires, Argentina},
series = {ISCA '24}
}

@inproceedings {mirage,
author = {Gururaj Saileshwar and Moinuddin Qureshi},
title = {{MIRAGE}: Mitigating {Conflict-Based} Cache Attacks with a Practical {Fully-Associative} Design},
booktitle = {30th USENIX Security Symposium (USENIX Security'21)},
year = {2021},
preview = {usec.png},
isbn = {978-1-939133-24-3},
pages = {1379--1396},
url = {https://www.usenix.org/conference/usenixsecurity21/presentation/saileshwar},
publisher = {USENIX Association},
month = aug
}

@conference{passp,
author={Nirmal Boran and Pranil Joshi and Virendra Singh},
title={PASS-P: Performance and Security Sensitive Dynamic Cache Partitioning},
booktitle={Proceedings of the 19th International Conference on Security and Cryptography - Volume 1: SECRYPT,},
year={2022},
pages={443-450},
publisher={SciTePress},
organization={INSTICC},
doi={10.5220/0011336900003283},
isbn={978-989-758-590-6},
}

@INPROCEEDINGS{ucp,
author={Qureshi, Moinuddin K. and Patt, Yale N.},
booktitle={2006 39th Annual IEEE/ACM International Symposium on Microarchitecture (MICRO'06)}, 
title={Utility-Based Cache Partitioning: A Low-Overhead, High-Performance, Runtime Mechanism to Partition Shared Caches}, 
year={2006},
preview = {micro-2006.gif},
volume={},
number={},
pages={423-432},
doi={10.1109/MICRO.2006.49}
}

@INPROCEEDINGS{freeflow,
author={Choudhary, Raj Kumar and Singh, Newton and Nair, Harideep and Rawat, Rishabh and Singh, Virendra},
booktitle={2019 IEEE 37th International Conference on Computer Design (ICCD)}, 
title={Freeflow Core: Enhancing Performance of In-Order Cores with Energy Efficiency}, 
year={2019},
volume={},
number={},
pages={702-705},
doi={10.1109/ICCD46524.2019.00103}
}

@INPROCEEDINGS{freeway,
author={Kumar, Rakesh and Alipour, Mehdi and Black-Schaffer, David},
booktitle={2019 IEEE International Symposium on High Performance Computer Architecture (HPCA)}, 
title={Freeway: Maximizing MLP for Slice-Out-of-Order Execution}, 
year={2019},
volume={},
number={},
pages={558-569},
doi={10.1109/HPCA.2019.00009}
}

@INPROCEEDINGS{load_slice,
author={Carlson, Trevor E. and Heirman, Wim and Allam, Osman and Kaxiras, Stefanos and Eeckhout, Lieven},
booktitle={2015 ACM/IEEE 42nd Annual International Symposium on Computer Architecture (ISCA)}, 
title={The Load Slice Core microarchitecture}, 
year={2015},
volume={},
number={},
pages={272-284},
doi={10.1145/2749469.2750407}
}


@inproceedings{adaptive,
author = {Zhao, Xia and Adileh, Almutaz and Yu, Zhibin and Wang, Zhiying and Jaleel, Aamer and Eeckhout, Lieven},
title = {Adaptive Memory-Side Last-Level GPU Caching},
year = {2019},
isbn = {9781450366694},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3307650.3322235},
doi = {10.1145/3307650.3322235},
abstract = {Emerging GPU applications exhibit increasingly high computation demands which has led GPU manufacturers to build GPUs with an increasingly large number of streaming multiprocessors (SMs). Providing data to the SMs at high bandwidth puts significant pressure on the memory hierarchy and the Network-on-Chip (NoC). Current GPUs typically partition the memory-side last-level cache (LLC) in equally-sized slices that are shared by all SMs. Although a shared LLC typically results in a lower miss rate, we find that for workloads with high degrees of data sharing across SMs, a private LLC leads to a significant performance advantage because of increased bandwidth to replicated cache lines across different LLC slices.In this paper, we propose adaptive memory-side last-level GPU caching to boost performance for sharing-intensive workloads that need high bandwidth to read-only shared data. Adaptive caching leverages a lightweight performance model that balances increased LLC bandwidth against increased miss rate under private caching. In addition to improving performance for sharing-intensive workloads, adaptive caching also saves energy in a (co-designed) hierarchical two-stage crossbar NoC by power-gating and bypassing the second stage if the LLC is configured as a private cache. Our experimental results using 17 GPU workloads show that adaptive caching improves performance by 28.1\% on average (up to 38.1\%) compared to a shared LLC for sharing-intensive workloads. In addition, adaptive caching reduces NoC energy by 26.6\% on average (up to 29.7\%) and total system energy by 6.1\% on average (up to 27.2\%) when configured as a private cache. Finally, we demonstrate through a GPU NoC design space exploration that a hierarchical two-stage crossbar is both more power- and area-efficient than full and concentrated crossbars with the same bisection bandwidth, thus providing a low-cost cooperative solution to exploit workload sharing behavior in memory-side last-level caches.},
booktitle = {Proceedings of the 46th International Symposium on Computer Architecture},
pages = {411–423},
numpages = {13},
location = {Phoenix, Arizona},
series = {ISCA '19}
}

@inproceedings{xgboost,
author = {Chen, Tianqi and Guestrin, Carlos},
title = {XGBoost: A Scalable Tree Boosting System},
year = {2016},
isbn = {9781450342322},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2939672.2939785},
doi = {10.1145/2939672.2939785},
abstract = {Tree boosting is a highly effective and widely used machine learning method. In this paper, we describe a scalable end-to-end tree boosting system called XGBoost, which is used widely by data scientists to achieve state-of-the-art results on many machine learning challenges. We propose a novel sparsity-aware algorithm for sparse data and weighted quantile sketch for approximate tree learning. More importantly, we provide insights on cache access patterns, data compression and sharding to build a scalable tree boosting system. By combining these insights, XGBoost scales beyond billions of examples using far fewer resources than existing systems.},
booktitle = {Proceedings of the 22nd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining},
pages = {785–794},
numpages = {10},
keywords = {large-scale machine learning},
location = {San Francisco, California, USA},
series = {KDD '16}
}

@INPROCEEDINGS{cmos,
author={Taylor, Brady and Ramos, Nicky and Yeats, Eric and Li, Hai},
booktitle={2022 IEEE 4th International Conference on Artificial Intelligence Circuits and Systems (AICAS)}, 
title={CMOS Implementation of Spiking Equilibrium Propagation for Real-Time Learning}, 
year={2022},
volume={},
number={},
pages={283-286},
doi={10.1109/AICAS54282.2022.9869989}
}

@ARTICLE{equi-prop,
AUTHOR={Scellier, Benjamin and Bengio, Yoshua},   
TITLE={Equilibrium Propagation: Bridging the Gap between Energy-Based Models and Backpropagation},      
JOURNAL={Frontiers in Computational Neuroscience},      
VOLUME={11},           
YEAR={2017},      
URL={https://www.frontiersin.org/articles/10.3389/fncom.2017.00024},       
DOI={10.3389/fncom.2017.00024},      
ISSN={1662-5188},   
}   

@article{sub02,
title={Sub-0.2 V Impact Ionization in Si n-i-p-i-n Diode},
author={Bhaskar Das and Sushama Sushama and J{\"o}rg Schulze and Udayan Ganguly},
journal={IEEE Transactions on Electron Devices},
year={2016},
volume={63},
pages={4668-4673},
url={https://api.semanticscholar.org/CorpusID:40330811}
}

@inproceedings{nipin,
author = {Meshram, Rohit and Das, Bhaskar and Mandapati, R. and Lashkare, Sandip and Deshmukh, Sanchit and Lodha, Saurabh and Ganguly, U. and Schulze, Jörg},
year = {2014},
month = {05},
pages = {1-4},
title = {High performance triangular barrier engineered NIPIN selector for bipolar RRAM},
isbn = {978-1-4799-3596-3},
journal = {2014 IEEE 6th International Memory Workshop, IMW 2014},
doi = {10.1109/IMW.2014.6849388}
}

@INPROCEEDINGS{halfnhalf,
  author={Yavarzadeh, Hosein and Taram, Mohammadkazem and Narayan, Shravan and Stefan, Deian and Tullsen, Dean},
  booktitle={2023 IEEE Symposium on Security and Privacy (SP)}, 
  title={Half&Half: Demystifying Intel’s Directional Branch Predictors for Fast, Secure Partitioned Execution}, 
  preview = {s&p.png},
  year={2023},
  pages={1220-1237},
  keywords={Privacy;Program processors;Side-channel attacks;Software;Hardware;Security;Branch-Prediction;Microarchitecture-Security;Side-Channel-Attacks;Directional-Branch-Predictor},
  doi={10.1109/SP46215.2023.10179415}
}
